{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPypXfMltDmJHs6kKOts1kK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemanthxin/DARVE/blob/main/DARVE_YOLOv8_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKxEkoLeA56n",
        "outputId": "19503fdb-b39e-4542-e861-5893251368d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics==8.1.0\n",
            "  Downloading ultralytics-8.1.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics==8.1.0)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (0.13.2)\n",
            "Collecting hub-sdk>=0.0.2 (from ultralytics==8.1.0)\n",
            "  Downloading hub_sdk-0.0.24-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics==8.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics==8.1.0) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.1.0) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.1.0) (1.17.0)\n",
            "Downloading ultralytics-8.1.0-py3-none-any.whl (699 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.2/699.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hub_sdk-0.0.24-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: hub-sdk, thop, ultralytics\n",
            "Successfully installed hub-sdk-0.0.24 thop-0.1.1.post2209072238 ultralytics-8.1.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.24)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.24.0+cpu)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics==8.1.0 torch torchvision torchaudio\n",
        "!pip install transformers timm scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/best.pt\n",
        "!file /content/best.pt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVZLskWoBYAr",
        "outputId": "e888e78e-6d46-4ba8-b14f-a87320057633"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 84M Jan 14 05:49 /content/best.pt\n",
            "/content/best.pt: Zip archive data, at least v0.0 to extract, compression method=store\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2\n",
        "!pip install ultralytics==8.1.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "opvnI2gxIiH5",
        "outputId": "0a76213d-98d6-4bd0-c2ea-ae361cb5d279"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.9.0+cpu\n",
            "Uninstalling torch-2.9.0+cpu:\n",
            "  Successfully uninstalled torch-2.9.0+cpu\n",
            "Found existing installation: torchvision 0.24.0+cpu\n",
            "Uninstalling torchvision-0.24.0+cpu:\n",
            "  Successfully uninstalled torchvision-0.24.0+cpu\n",
            "Found existing installation: torchaudio 2.9.0+cpu\n",
            "Uninstalling torchaudio-2.9.0+cpu:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cpu\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0, 2.9.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.1.2\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: ultralytics==8.1.0 in /usr/local/lib/python3.12/dist-packages (8.1.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (1.16.3)\n",
            "Collecting torch>=1.8.0 (from ultralytics==8.1.0)\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchvision>=0.9.0 (from ultralytics==8.1.0)\n",
            "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (0.13.2)\n",
            "Requirement already satisfied: hub-sdk>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.1.0) (0.0.24)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics==8.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics==8.1.0) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.1.0) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.1.0) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.1.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.1.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.1.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.1 (from torch>=1.8.0->ultralytics==8.1.0)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.1.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics==8.1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.1.0) (3.0.3)\n",
            "Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m954.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.29.2\n",
            "    Uninstalling nvidia-nccl-cu12-2.29.2:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.29.2\n",
            "Successfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 torch-2.9.1 torchvision-0.24.1 triton-3.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchvision"
                ]
              },
              "id": "771859e171a7436aab7fec2e8bedf160"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import ultralytics.nn.tasks\n",
        "\n",
        "torch.serialization.add_safe_globals([\n",
        "    ultralytics.nn.tasks.DetectionModel\n",
        "])\n"
      ],
      "metadata": {
        "id": "oLcVT5pxGTIg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import ultralytics.nn.modules.conv\n",
        "import ultralytics.nn.modules.block\n",
        "import ultralytics.nn.modules.head\n",
        "\n",
        "# Add necessary classes to safe globals for unpickling\n",
        "torch.serialization.add_safe_globals([\n",
        "    torch.nn.modules.container.Sequential,\n",
        "    ultralytics.nn.modules.conv.Conv,\n",
        "    torch.nn.modules.conv.Conv2d,\n",
        "    torch.nn.modules.batchnorm.BatchNorm2d,\n",
        "    torch.nn.modules.activation.SiLU,\n",
        "    ultralytics.nn.modules.block.C2f,\n",
        "    torch.nn.modules.container.ModuleList,\n",
        "    ultralytics.nn.modules.block.Bottleneck,\n",
        "    ultralytics.nn.modules.block.SPPF,\n",
        "    torch.nn.modules.pooling.MaxPool2d,\n",
        "    torch.nn.modules.upsampling.Upsample,\n",
        "    ultralytics.nn.modules.conv.Concat,\n",
        "    ultralytics.nn.modules.head.Detect,\n",
        "    ultralytics.nn.modules.block.DFL\n",
        "])\n",
        "\n",
        "torch.load(\"/content/best.pt\", weights_only=False)\n",
        "model = YOLO(\"/content/best.pt\", task=\"detect\")"
      ],
      "metadata": {
        "id": "4CdZeIPLHMlI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9WvL1gRrMyeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLO MODEL LOADING"
      ],
      "metadata": {
        "id": "v1F5QwHpgspC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"/content/best.pt\", task=\"detect\")\n",
        "print(\"YOLO model loaded successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi6N1mW9Dz9_",
        "outputId": "9c01cf45-db20-4606-8c1e-70533d1ca4ab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIT DATASET"
      ],
      "metadata": {
        "id": "gbEbt3Sgg0dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, random\n",
        "\n",
        "base = \"/content/vit_lamp_dataset\"\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "classes = [\"ON\", \"OFF\"]\n",
        "\n",
        "# Create folders\n",
        "for s in splits:\n",
        "    for c in classes:\n",
        "        os.makedirs(f\"{base}/{s}/{c}\", exist_ok=True)\n",
        "\n",
        "# Manually list images (adjust if filenames differ)\n",
        "ON_images = [\n",
        "    \"/content/vit_lamp_dataset/online-puja.jpg\",\n",
        "    \"/content/vit_lamp_dataset/SriMalaiperumalIdol.jpg\",\n",
        "    \"/content/vit_lamp_dataset/images (4).jpg\",\n",
        "    \"/content/vit_lamp_dataset/images (3).jpg\",\n",
        "    \"/content/vit_lamp_dataset/images (2).jpg\",\n",
        "    \"/content/vit_lamp_dataset/images (1).jpg\",\n",
        "    \"/content/vit_lamp_dataset/4d9df308f558b1a04d6e1b55714ad4b3.jpg\",\n",
        "    \"/content/vit_lamp_dataset/1abd640fc2550ea8c3d563744393aa5b.jpg\",\n",
        "    \"/content/vit_lamp_dataset/WhatsApp Image 2026-01-14 at 1.05.11 PM.jpeg\",\n",
        "    \"/content/vit_lamp_dataset/WhatsApp Image 2026-01-14 at 1.05.12 PM.jpeg\",\n",
        "    \"/content/vit_lamp_dataset/How_to_Worship_Tirupati_Balaji_Idol_at_Home_Easily_7165b689-866a-4a8e-ae0d-0bc7a086fbec.webp\"\n",
        "]\n",
        "\n",
        "OFF_images = [\n",
        "    \"/content/vit_lamp_dataset/images (5).jpg\",\n",
        "    \"/content/vit_lamp_dataset/61nybWUdHML._AC_UF350,350_QL80_.jpg\"\n",
        "]\n",
        "\n",
        "random.shuffle(ON_images)\n",
        "random.shuffle(OFF_images)\n",
        "\n",
        "def split_copy(images, label):\n",
        "    train = images[:int(0.6*len(images))]\n",
        "    val   = images[int(0.6*len(images)):int(0.8*len(images))]\n",
        "    test  = images[int(0.8*len(images)):]\n",
        "\n",
        "    for img in train:\n",
        "        shutil.copy(img, f\"{base}/train/{label}/\")\n",
        "    for img in val:\n",
        "        shutil.copy(img, f\"{base}/val/{label}/\")\n",
        "    for img in test:\n",
        "        shutil.copy(img, f\"{base}/test/{label}/\")\n",
        "\n",
        "split_copy(ON_images, \"ON\")\n",
        "split_copy(OFF_images, \"OFF\")\n",
        "\n",
        "print(\"ViT dataset created successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YKTMAcmEXnx",
        "outputId": "fddeaf7a-4303-451d-8943-99799b07a1ac"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT dataset created successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find vit_lamp_dataset -type f | wc -l\n",
        "!find vit_lamp_dataset/train -type f\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ICG7LULWD-H",
        "outputId": "b1a8c6c0-372e-47b8-f49c-d2c91d85d2e4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n",
            "vit_lamp_dataset/train/OFF/images (5).jpg\n",
            "vit_lamp_dataset/train/ON/How_to_Worship_Tirupati_Balaji_Idol_at_Home_Easily_7165b689-866a-4a8e-ae0d-0bc7a086fbec.webp\n",
            "vit_lamp_dataset/train/ON/1abd640fc2550ea8c3d563744393aa5b.jpg\n",
            "vit_lamp_dataset/train/ON/4d9df308f558b1a04d6e1b55714ad4b3.jpg\n",
            "vit_lamp_dataset/train/ON/WhatsApp Image 2026-01-14 at 1.05.12 PM.jpeg\n",
            "vit_lamp_dataset/train/ON/images (3).jpg\n",
            "vit_lamp_dataset/train/ON/images (2).jpg\n",
            "vit_lamp_dataset/train/ON/images (1).jpg\n",
            "vit_lamp_dataset/train/ON/online-puja.jpg\n",
            "vit_lamp_dataset/train/ON/images (4).jpg\n",
            "vit_lamp_dataset/train/ON/SriMalaiperumalIdol.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find vit_lamp_dataset -type d\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMon1hxaWE8A",
        "outputId": "c748ab59-4ec2-44c5-940b-cf632da18195"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vit_lamp_dataset\n",
            "vit_lamp_dataset/val\n",
            "vit_lamp_dataset/val/OFF\n",
            "vit_lamp_dataset/val/ON\n",
            "vit_lamp_dataset/train\n",
            "vit_lamp_dataset/train/OFF\n",
            "vit_lamp_dataset/train/ON\n",
            "vit_lamp_dataset/test\n",
            "vit_lamp_dataset/test/OFF\n",
            "vit_lamp_dataset/test/ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers timm accelerate scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDt5K4_lW8kz",
        "outputId": "b047ddc4-ba95-40d8-8172-8217ced3d8bd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.24)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.9.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "fu9enSV7XIuu"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIT IMAGE TRANSFORM"
      ],
      "metadata": {
        "id": "bvOAjQj2g847"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processor = ViTImageProcessor.from_pretrained(\n",
        "    \"google/vit-base-patch16-224\"\n",
        ")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=processor.image_mean,\n",
        "        std=processor.image_std\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "Kj1liypfXuOz"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLASS MAPPING"
      ],
      "metadata": {
        "id": "93ZqBymUhH_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = datasets.ImageFolder(\n",
        "    \"vit_lamp_dataset/train\",\n",
        "    transform=transform\n",
        ")\n",
        "val_ds = datasets.ImageFolder(\n",
        "    \"vit_lamp_dataset/val\",\n",
        "    transform=transform\n",
        ")\n",
        "test_ds = datasets.ImageFolder(\n",
        "    \"vit_lamp_dataset/test\",\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=4)\n",
        "test_loader = DataLoader(test_ds, batch_size=4)\n",
        "\n",
        "print(\"Class mapping:\", train_ds.class_to_idx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv62EdAxYE5E",
        "outputId": "cfe81241-0048-425a-a8c2-938a75fa1f6b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class mapping: {'OFF': 0, 'ON': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIT IMAGE CLASSIFICATION"
      ],
      "metadata": {
        "id": "yMNKXjl8hMTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViTForImageClassification.from_pretrained(\n",
        "    \"google/vit-base-patch16-224\",\n",
        "    num_labels=2,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-CFmkz4YQbU",
        "outputId": "0cfc579d-8148-4f70-a6d2-78b943443b7c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.vit.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "-BzqAExWZEQa"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.classifier.parameters(),\n",
        "    lr=1e-3\n",
        ")\n"
      ],
      "metadata": {
        "id": "tQIzJbU6ZZHL"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN LOOP"
      ],
      "metadata": {
        "id": "kU_KmNPUhpkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 8\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(pixel_values=imgs)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    preds, gts = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            outputs = model(pixel_values=imgs)\n",
        "            preds.extend(outputs.logits.argmax(dim=1).cpu().tolist())\n",
        "            gts.extend(labels.tolist())\n",
        "\n",
        "    acc = accuracy_score(gts, preds)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
        "        f\"Train Loss: {total_loss:.3f} | \"\n",
        "        f\"Val Acc: {acc:.3f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5tW5LYYZeq4",
        "outputId": "f28bce7c-c5d5-4aaf-8e8c-a31a02b4207b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8 | Train Loss: 1.985 | Val Acc: 0.857\n",
            "Epoch 2/8 | Train Loss: 0.684 | Val Acc: 0.857\n",
            "Epoch 3/8 | Train Loss: 0.665 | Val Acc: 0.857\n",
            "Epoch 4/8 | Train Loss: 0.633 | Val Acc: 0.857\n",
            "Epoch 5/8 | Train Loss: 0.516 | Val Acc: 0.857\n",
            "Epoch 6/8 | Train Loss: 0.413 | Val Acc: 0.857\n",
            "Epoch 7/8 | Train Loss: 0.259 | Val Acc: 1.000\n",
            "Epoch 8/8 | Train Loss: 0.111 | Val Acc: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVING VIT MODEL"
      ],
      "metadata": {
        "id": "GelL_hJjhbMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/vit_lamp_model\")\n",
        "processor.save_pretrained(\"/content/vit_lamp_model\")\n",
        "\n",
        "print(\"ViT model saved\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okrrCvfyZiZW",
        "outputId": "4a0f967d-9b10-44ed-bde8-fd7fcca9e9c6"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INFERENCE"
      ],
      "metadata": {
        "id": "Sb1KuOEXhyey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "img = Image.open(\"vit_lamp_dataset/test/ON/\" +\n",
        "                 os.listdir(\"vit_lamp_dataset/test/ON\")[0])\n",
        "\n",
        "img_t = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = model(pixel_values=img_t)\n",
        "    probs = torch.softmax(out.logits, dim=1)\n",
        "\n",
        "print({\n",
        "    \"OFF\": float(probs[0][0]),\n",
        "    \"ON\": float(probs[0][1])\n",
        "})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaWhGfawac6K",
        "outputId": "eabf9e31-7ef6-4296-c1ee-1cae1078bbc7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'OFF': 0.03009096346795559, 'ON': 0.9699090123176575}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIAMESE CNN — FULL TRAINING CODE (POC)"
      ],
      "metadata": {
        "id": "JfdiFyoTebgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import random\n"
      ],
      "metadata": {
        "id": "deFOqx32anNT"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMAGE TRANSFORMS"
      ],
      "metadata": {
        "id": "95oiQdXxe4mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "48WniEjbeuXQ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINE IMAGE PAIRS"
      ],
      "metadata": {
        "id": "MpHzaMgffDMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [\n",
        "    (\"SriMalaiperumalIdol.jpg\", \"SriMalaiperumalIdol.jpg\", 1),\n",
        "    (\"SriMalaiperumalIdol.jpg\", \"online-puja.jpg\", 0),\n",
        "    (\"images (4).jpg\", \"images (4).jpg\", 1),\n",
        "    (\"images (5).jpg\", \"106031861.avif\", 0),\n",
        "    (\"images (3).jpg\", \"images (3).jpg\", 1),\n",
        "    (\"images (2).jpg\", \"Screenshot 2026-01-13 163738.png\", 0),\n",
        "]\n"
      ],
      "metadata": {
        "id": "Xwt6nQ9VeyXm"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATASET CLASS"
      ],
      "metadata": {
        "id": "nz_1NZLEfcZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img1, img2, label = self.pairs[idx]\n",
        "\n",
        "        img1 = transform(Image.open(img1).convert(\"RGB\"))\n",
        "        img2 = transform(Image.open(img2).convert(\"RGB\"))\n",
        "\n",
        "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "mcAnG21zfYTM"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIAMESE MODEL"
      ],
      "metadata": {
        "id": "mbctqkk4ft1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        backbone = models.resnet18(pretrained=True)\n",
        "        self.encoder = nn.Sequential(*list(backbone.children())[:-1])\n",
        "        self.fc = nn.Linear(512, 128)\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        return self.forward_once(x1), self.forward_once(x2)\n"
      ],
      "metadata": {
        "id": "ZQLwYLqRfno7"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN SETUP"
      ],
      "metadata": {
        "id": "r3gB6nX5f4JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = SiameseNet().to(device)\n",
        "criterion = nn.CosineEmbeddingLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "dataset = SiameseDataset(pairs)\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "di8gFJxxfzQl"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN LOOP"
      ],
      "metadata": {
        "id": "gd2aHiSIf_BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "\n",
        "    for img1, img2, label in loader:\n",
        "        img1, img2 = img1.to(device), img2.to(device)\n",
        "        label = label.to(device)\n",
        "        label = label * 2 - 1  # Convert 0/1 → -1/1\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out1, out2 = model(img1, img2)\n",
        "        loss = criterion(out1, out2, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qbfdzAJgFlR",
        "outputId": "f2c999f7-fd40-4899-919c-7ea51f7262ee"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 1.0024\n",
            "Epoch 2/10 | Loss: 0.7420\n",
            "Epoch 3/10 | Loss: 0.1405\n",
            "Epoch 4/10 | Loss: 0.1297\n",
            "Epoch 5/10 | Loss: 0.0587\n",
            "Epoch 6/10 | Loss: 0.0710\n",
            "Epoch 7/10 | Loss: 0.0485\n",
            "Epoch 8/10 | Loss: 0.3115\n",
            "Epoch 9/10 | Loss: 0.0282\n",
            "Epoch 10/10 | Loss: 0.0606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INFERENCE"
      ],
      "metadata": {
        "id": "6ttDEpTUiT7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def similarity(imgA, imgB):\n",
        "    imgA = transform(Image.open(imgA).convert(\"RGB\")).unsqueeze(0).to(device)\n",
        "    imgB = transform(Image.open(imgB).convert(\"RGB\")).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        embA, embB = model(imgA, imgB)\n",
        "        score = F.cosine_similarity(embA, embB).item()\n",
        "\n",
        "    return round(score, 3)\n",
        "\n",
        "print(similarity(\"SriMalaiperumalIdol.jpg\", \"SriMalaiperumalIdol.jpg\"))\n",
        "print(similarity(\"images (3).jpg\", \"Screenshot 2026-01-13 163738.png\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wa5lct4f8o3",
        "outputId": "335ac815-8340-478b-92b2-e2ad4186c4bf"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DARVE-CORE — FINAL INTEGRATION\n",
        "\n",
        "YOLO + ViT + Siamese → One Decision\n",
        "\n",
        "1. darve_yolo.py — Object Presence"
      ],
      "metadata": {
        "id": "Az05zCpFjsej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile darve_yolo.py\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import ultralytics.nn.modules.conv\n",
        "import ultralytics.nn.modules.block\n",
        "import ultralytics.nn.modules.head\n",
        "\n",
        "# 🔒 Allow Ultralytics classes for PyTorch 2.6+\n",
        "torch.serialization.add_safe_globals([\n",
        "    torch.nn.modules.container.Sequential,\n",
        "    ultralytics.nn.modules.conv.Conv,\n",
        "    torch.nn.modules.conv.Conv2d,\n",
        "    torch.nn.modules.batchnorm.BatchNorm2d,\n",
        "    torch.nn.modules.activation.SiLU,\n",
        "    ultralytics.nn.modules.block.C2f,\n",
        "    torch.nn.modules.container.ModuleList,\n",
        "    ultralytics.nn.modules.block.Bottleneck,\n",
        "    ultralytics.nn.modules.block.SPPF,\n",
        "    torch.nn.modules.pooling.MaxPool2d,\n",
        "    torch.nn.modules.upsampling.Upsample,\n",
        "    ultralytics.nn.modules.conv.Concat,\n",
        "    ultralytics.nn.modules.head.Detect,\n",
        "    ultralytics.nn.modules.block.DFL,\n",
        "    ultralytics.nn.tasks.DetectionModel,\n",
        "])\n",
        "\n",
        "# Load YOLO safely\n",
        "yolo = YOLO(\"/content/best.pt\")\n",
        "\n",
        "def get_object_score(image_path: str) -> float:\n",
        "    results = yolo(image_path, conf=0.3)\n",
        "    boxes = results[0].boxes\n",
        "\n",
        "    if boxes is None or len(boxes) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    scores = [float(b.conf) for b in boxes]\n",
        "    return round(sum(scores) / len(scores), 3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AftFGIoYk8It",
        "outputId": "77ac5707-b381-4bb8-9535-6ed87fb89641"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting darve_yolo.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. darve_vit.py — Lamp ON / OFF"
      ],
      "metadata": {
        "id": "0cGuDK_flClC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile darve_vit.py\n",
        "import torch\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    \"/content/vit_lamp_model\"\n",
        ").to(device)\n",
        "model.eval()\n",
        "\n",
        "processor = ViTImageProcessor.from_pretrained(\n",
        "    \"/content/vit_lamp_model\"\n",
        ")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=processor.image_mean,\n",
        "        std=processor.image_std\n",
        "    )\n",
        "])\n",
        "\n",
        "def get_ritual_score(image_path: str) -> float:\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(pixel_values=img).logits\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "\n",
        "    # Index 1 = ON\n",
        "    return round(float(probs[0][1]), 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WYnpIeMiXBv",
        "outputId": "480d3065-3dbd-44b1-c305-f3eacb2c4f9b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing darve_vit.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. darve_siamese.py — Scene Consistency"
      ],
      "metadata": {
        "id": "TkzdQtSmlP3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile darve_siamese.py\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "class SiameseNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        backbone = models.resnet18(pretrained=True)\n",
        "        self.encoder = torch.nn.Sequential(*list(backbone.children())[:-1])\n",
        "        self.fc = torch.nn.Linear(512, 128)\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        return self.forward_once(x1), self.forward_once(x2)\n",
        "\n",
        "model = SiameseNet().to(device)\n",
        "model.eval()  # PoC model\n",
        "\n",
        "def get_scene_score(img_today: str, img_yesterday: str) -> float:\n",
        "    img1 = transform(Image.open(img_today).convert(\"RGB\")).unsqueeze(0).to(device)\n",
        "    img2 = transform(Image.open(img_yesterday).convert(\"RGB\")).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        e1, e2 = model(img1, img2)\n",
        "        score = F.cosine_similarity(e1, e2).item()\n",
        "\n",
        "    return round(score, 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXBuK8atlN8a",
        "outputId": "18665043-2068-4ef4-bc61-aeec707d155b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing darve_siamese.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. darve_core.py — THE BRAIN"
      ],
      "metadata": {
        "id": "yDQ_Fj2flmsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile darve_core.py\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "\n",
        "@dataclass\n",
        "class DarveSignals:\n",
        "    object_score: float\n",
        "    ritual_score: float\n",
        "    scene_score: float\n",
        "\n",
        "@dataclass\n",
        "class DarveResult:\n",
        "    status: str\n",
        "    confidence: float\n",
        "    reasons: List[str]\n",
        "\n",
        "def darve_decide(s: DarveSignals) -> DarveResult:\n",
        "    reasons = []\n",
        "\n",
        "    if s.object_score < 0.5:\n",
        "        reasons.append(\"Ritual objects missing\")\n",
        "\n",
        "    if s.ritual_score < 0.6:\n",
        "        reasons.append(\"Lamp not lit\")\n",
        "\n",
        "    if s.scene_score < 0.7:\n",
        "        reasons.append(\"Different shrine detected\")\n",
        "\n",
        "    confidence = round(\n",
        "        0.4 * s.object_score +\n",
        "        0.4 * s.ritual_score +\n",
        "        0.2 * s.scene_score,\n",
        "        3\n",
        "    )\n",
        "\n",
        "    if confidence >= 0.80:\n",
        "        status = \"POOJA_DONE\"\n",
        "    elif confidence >= 0.6:\n",
        "        status = \"UNCLEAR\"\n",
        "    else:\n",
        "        status = \"POOJA_NOT_DONE\"\n",
        "\n",
        "    return DarveResult(\n",
        "        status=status,\n",
        "        confidence=confidence,\n",
        "        reasons=reasons if reasons else [\"All checks passed\"]\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJq812j4llMW",
        "outputId": "383b5fc0-df51-4d47-cfc6-87cfb1516b03"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting darve_core.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. test_darve.py — END-TO-END TEST"
      ],
      "metadata": {
        "id": "XhNQTNc8l0Jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_darve.py\n",
        "from darve_yolo import get_object_score\n",
        "from darve_vit import get_ritual_score\n",
        "from darve_siamese import get_scene_score\n",
        "from darve_core import DarveSignals, darve_decide\n",
        "\n",
        "img_today = \"SriMalaiperumalIdol.jpg\"\n",
        "img_yesterday = \"SriMalaiperumalIdol.jpg\"\n",
        "\n",
        "signals = DarveSignals(\n",
        "    object_score=get_object_score(img_today),\n",
        "    ritual_score=get_ritual_score(img_today),\n",
        "    scene_score=get_scene_score(img_today, img_yesterday)\n",
        ")\n",
        "\n",
        "result = darve_decide(signals)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYAX0FPelzCQ",
        "outputId": "b8b7a452-f16b-4089-9b11-01b792da0ba0"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_darve.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_darve.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxjbEcfXmId8",
        "outputId": "cc3fae6d-5a73-4038-e096-60ca7771d67f"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-14 08:41:32.302699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768380092.328132   44895 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768380092.336071   44895 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768380092.359239   44895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768380092.359288   44895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768380092.359293   44895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768380092.359298   44895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "\n",
            "image 1/1 /content/SriMalaiperumalIdol.jpg: 640x480 17 deitys, 1 lamp, 1 flowers, 2189.9ms\n",
            "Speed: 5.6ms preprocess, 2189.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "DarveResult(status='POOJA_DONE', confidence=0.841, reasons=['All checks passed'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "1011e42c",
        "outputId": "2648251d-e2e1-494a-b101-a37906fa261e"
      },
      "source": [
        "import subprocess\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Run the test_darve.py script and capture its output\n",
        "result = subprocess.run(['python', 'test_darve.py'], capture_output=True, text=True)\n",
        "output_str = result.stdout.strip()\n",
        "\n",
        "# Parse the output string\n",
        "# Example output: DarveResult(status='POOJA_DONE', confidence=0.841, reasons=['All checks passed'])\n",
        "status_match = re.search(r\"status='([^']+)'\", output_str)\n",
        "confidence_match = re.search(r\"confidence=([\\d.]+)\", output_str)\n",
        "reasons_match = re.search(r\"reasons=\\[([^]]*)\\]\", output_str)\n",
        "\n",
        "status = status_match.group(1) if status_match else 'N/A'\n",
        "confidence = float(confidence_match.group(1)) if confidence_match else 'N/A'\n",
        "reasons_str = reasons_match.group(1) if reasons_match else ''\n",
        "reasons = [r.strip(\"'\") for r in reasons_str.split(',')] if reasons_str else []\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "df_result = pd.DataFrame({\n",
        "    'Metric': ['Status', 'Confidence', 'Reasons'],\n",
        "    'Value': [status, confidence, ', '.join(reasons)]\n",
        "})\n",
        "\n",
        "# Display the DataFrame\n",
        "display(df_result)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Metric              Value\n",
              "0      Status         POOJA_DONE\n",
              "1  Confidence              0.836\n",
              "2     Reasons  All checks passed"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-397e917f-2c85-4023-a63f-bb7dc334a77a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Status</td>\n",
              "      <td>POOJA_DONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Confidence</td>\n",
              "      <td>0.836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Reasons</td>\n",
              "      <td>All checks passed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-397e917f-2c85-4023-a63f-bb7dc334a77a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-397e917f-2c85-4023-a63f-bb7dc334a77a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-397e917f-2c85-4023-a63f-bb7dc334a77a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_4da1910b-1f4c-46c0-99ea-15cea1616bf6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_result')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4da1910b-1f4c-46c0-99ea-15cea1616bf6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_result');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_result",
              "summary": "{\n  \"name\": \"df_result\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Status\",\n          \"Confidence\",\n          \"Reasons\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"POOJA_DONE\",\n          0.836,\n          \"All checks passed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kwxhNi7ooEkl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}